{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Input, Embedding, Dense, Dropout, GlobalAveragePooling1D\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Transformer-based model\n",
    "class TransformerModel(Model):\n",
    "    def __init__(self, num_heads, d_model, dff, input_vocab_size, maximum_position_encoding, dropout_rate=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = self.positional_encoding(maximum_position_encoding, d_model)\n",
    "        self.encoder_layer = tf.keras.layers.TransformerEncoderLayer(d_model, num_heads, dff, dropout_rate)\n",
    "        self.encoder = tf.keras.layers.TransformerEncoder(self.encoder_layer, num_layers)\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.fc = Dense(input_vocab_size, activation='softmax')\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n",
    "        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "        pos_encoding = angle_rads[np.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "    def get_angles(self, positions, i, d_model):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "        return positions * angle_rates\n",
    "\n",
    "    def call(self, x):\n",
    "        seq_length = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(embedding_size, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_length, :]\n",
    "        x = self.encoder(x)\n",
    "        x = self.dropout(x)\n",
    "        x = GlobalAveragePooling1D()(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Define model hyperparameters\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "dff = 512\n",
    "dropout_rate = 0.1\n",
    "input_vocab_size = len(tokenizer.word_index) + 1\n",
    "maximum_position_encoding = 10000\n",
    "\n",
    "# Instantiate the Transformer model\n",
    "model = TransformerModel(num_heads, embedding_size, dff, input_vocab_size, maximum_position_encoding, dropout_rate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
