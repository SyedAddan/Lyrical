{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "from transformers import pipeline\n",
    "\n",
    "model_ckpt = \"papluca/xlm-roberta-base-language-detection\"\n",
    "pipe = pipeline(\"text-classification\", model=model_ckpt, device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code identifies the language of the lyrics\n",
    "def identify_language(lyrics: str) -> str|np.nan:\n",
    "    res = pipe([lyrics], truncation=True, max_length=128)\n",
    "    return res[0]['label'] if res[0]['score'] > 0.5 else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can take more than 12 hours to run\n",
    "with pd.read_csv(\n",
    "    \"../data/raw/song_lyrics.csv\",\n",
    "    chunksize=5 * 10**4,\n",
    "    usecols=[\"title\", \"artist\", \"year\", \"tag\", \"views\", \"lyrics\"],\n",
    "    dtype={\"year\": np.int16, \"views\": np.int32}\n",
    ") as chunks:\n",
    "\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        print(f\"Processing chunk {idx}\")\n",
    "\n",
    "        # drop N.A. lyrics\n",
    "        chunk = chunk.dropna(subset=[\"lyrics\"])\n",
    "        \n",
    "        # drop romanizations\n",
    "        chunk = chunk[chunk[\"artist\"] != \"Genius Romanizations\"]\n",
    "        chunk = chunk[~chunk[\"title\"].str.contains(r\"\\(?romanized\\)?\", regex=True, na=False, case=False)]\n",
    "\n",
    "        # remove invalid years\n",
    "        chunk = chunk[chunk[\"year\"] < 2023]\n",
    "        \n",
    "        # remove duplicated entries\n",
    "        chunk = chunk.drop_duplicates(subset=[\"title\", \"artist\", \"year\"])\n",
    "        \n",
    "        # remove special characters from lyrics\n",
    "        pattern = r\"(?m)^\\[.*?\\]$\"\n",
    "        chunk[\"lyrics\"] = chunk[\"lyrics\"].str.replace(pattern, \"\", regex=True)\n",
    "        \n",
    "        # remove empty lines\n",
    "        pattern = r\"\\n|\\n\\n\"\n",
    "        chunk[\"lyrics\"] = chunk[\"lyrics\"].str.replace(pattern, \" \", regex=True)\n",
    "\n",
    "        # drop lyrics that are too short or too long\n",
    "        chunk = chunk[chunk[\"lyrics\"].str.len().between(10**2, 10**5)]\n",
    "\n",
    "        # analyze language\n",
    "        chunk[\"language\"] = chunk[\"lyrics\"].apply(identify_language)\n",
    "        print(f'{len(chunk[chunk[\"language_cld3\"].isna()])} not identified lyrics using by the language detection model.')\n",
    "        \n",
    "        # drop non-english lyrics\n",
    "        chuck = chunk[chunk[\"language\"] == \"en\"][[\"artist\", \"tag\", \"lyrics\"]]\n",
    "        \n",
    "        # save processed data\n",
    "        chunk.to_csv(\"../data/processed/lyrics_processed.csv\", mode=\"a\", header=not os.path.exists(\"../data/processed/lyrics_processed.csv\"), index=False)\n",
    "        \n",
    "        del chunk\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the semi-processed data\n",
    "semi_processed = pd.read_csv(\"../data/processed/lyrics_processed.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the views column and renaming the tag and title columns\n",
    "semi_processed_2 = semi_processed.drop(columns=[\"views\"]).rename({\"tag\":\"genre\", \"title\":\"song\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some sets for min year, max years and best 100 artists\n",
    "maxes = set()\n",
    "mins = set()\n",
    "best_100_artists = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function prints the artist, first song year, last song year, number of songs released, and the best 100 artists so far\n",
    "# It gets the data for the artist from my own personal tastes, some websites and some artists I knew were popular\n",
    "def artister(artist):\n",
    "    if artist in semi_processed_2[\"artist\"].unique() and artist not in best_100_artists:\n",
    "        data_artist = semi_processed_2[semi_processed_2[\"artist\"] == artist]\n",
    "        maxes.add(data_artist.year.max())\n",
    "        mins.add(data_artist.year.min())\n",
    "        best_100_artists.add(artist)\n",
    "        print(f\"Artist: {artist}\")\n",
    "        print(f\"First Song Released In: {data_artist.year.min()}\")\n",
    "        print(f\"Last Song Released In: {data_artist.year.max()}\")\n",
    "        print(f\"Number of Songs Released: {len(data_artist)}\")\n",
    "        print(f\"So far: {best_100_artists}\")\n",
    "        print(f\"So far this many: {len(best_100_artists)}\")\n",
    "        print(f\"First Song Years: {mins}\")\n",
    "        print(f\"First First Song Year: {min(mins)}\")\n",
    "        print(f\"Last Song Years: {maxes}\")\n",
    "        print(f\"Last Last Song Year: {max(maxes)}\")\n",
    "    else:\n",
    "        print(\"No Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After scrapping my own personal tastes, some websites and some artists I knew were popular, I came up with this list of 100 artists.\n",
    "best_100_artists = {'Led Zeppelin', 'LSD', 'Jon Hopkins', 'Dolly Parton', 'Billy Joel', 'Backstreet Boys', 'Muze Sikk', 'Kanye West', 'SALES', 'Ray Charles', 'Gucci Mane', 'Rihanna', 'Aerosmith', 'Juice WRLD', 'Soulja Boy', 'Snoop Dogg', 'Bon Jovi', 'twenty one pilots', 'Alabama', 'Kid Cudi', 'The Drums', 'Eminem', 'alt-J', 'AC/DC', 'Of Monsters and Men', 'Madonna', 'James Brown', 'Britney Spears', 'Johnny Cash', 'Guided by Voices', 'Bruce Springsteen', 'The White Stripes', 'The Rolling Stones', 'Tyler', 'Arctic Monkeys', 'Shania Twain', '50 Cent', 'Eagles', 'The Game', 'Maroon 5', 'Caravan Palace', 'Emily Dickinson', 'LMFAO', 'Rod Stewart', 'Imagine Dragons', 'june', 'Sia', 'Daft Punk', 'Kendrick Lamar', 'Matthew Mole', 'Shakira', 'Jack Stauber', 'U2', 'Katy Perry', 'Pink Floyd', 'Glee Cast', 'Taylor Swift', 'Radiohead', 'Frank Zappa', 'Whitney Houston', 'Bob Dylan', 'Abraham Lincoln', 'The Beatles', 'Stevie Wonder', 'Lil B', 'Marshmello', 'Queen', 'Mariah Carey', 'Metallica', 'JP Saxe', 'Elton John', 'Noah Kahan', 'Macklemore', 'Harry Styles', 'Prince', 'Frank Sinatra', 'Ed Sheeran', 'J. Cole', 'Burial', 'Michael Jackson', '2Pac', 'Ella Fitzgerald', 'The Weeknd', 'Joji', 'The Grateful Dead', 'Bruno Mars', 'Shawn Mendes', 'Miley Cyrus', 'Lil Wayne', 'Adele', 'Nirvana', 'Clean Bandit', 'Avril Lavigne', \"Guns N' Roses\", 'Drake', 'Coldplay', 'Black Eyed Peas', 'Van Morrison', 'AURORA', 'Elvis Presley'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data to only include the best 100 artists\n",
    "semi_processed_3 = semi_processed_2[semi_processed_2['artist'].isin(best_100_artists)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing only the 100 most popular artists\n",
    "semi_processed_4 = semi_processed_3[semi_processed_3['year'] > 1950]\n",
    "semi_processed_4 = semi_processed_4.astype({\"year\":np.int16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the misc genre\n",
    "semi_processed_5 = semi_processed_4[semi_processed_4['genre'] != 'misc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3373529\n",
      "46575\n",
      "45993\n",
      "42803\n"
     ]
    }
   ],
   "source": [
    "# Printing the length of each dataset\n",
    "print(len(semi_processed_2))\n",
    "print(len(semi_processed_3))\n",
    "print(len(semi_processed_4))\n",
    "print(len(semi_processed_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pop        13427\n",
       "rock       12694\n",
       "rap        11724\n",
       "country     2713\n",
       "rb          2245\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_processed_5.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So Lastly we have 100 artists, 5 genres (pop, rock, rap, country, rb), 72 years (ranging from 1951 to 2022) and 42,803 songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data\n",
    "semi_processed_5.to_csv(\"../data/processed/lyrics_processed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
