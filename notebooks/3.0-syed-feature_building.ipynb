{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Lambda, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Load the ELMo model\n",
    "elmo = hub.load(\"https://tfhub.dev/google/elmo/3\")\n",
    "\n",
    "# Load the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to preprocess the lyrics and generate ELMo embeddings\n",
    "def elmo_embeddings(lyrics):\n",
    "    embeddings = elmo(lyrics, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "    return K.squeeze(K.slice(embeddings, [0, 0, 0], [-1, -1, -1]), axis=0)\n",
    "\n",
    "# Function to preprocess the lyrics and generate BERT embeddings\n",
    "def bert_embeddings(lyrics):\n",
    "    input_ids = tf.constant(tokenizer.encode(lyrics))[None, :]\n",
    "    outputs = bert_model(input_ids)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    return K.squeeze(embeddings, axis=0)\n",
    "\n",
    "# Load your lyrics dataset from the CSV file\n",
    "dataset = pd.read_csv('lyrics_dataset.csv')\n",
    "\n",
    "# Preprocess the lyrics column\n",
    "lyrics = dataset['lyrics'].tolist()\n",
    "\n",
    "# Use ThreadPoolExecutor to parallelize embedding generation\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    # Generate ELMo embeddings\n",
    "    elmo_embeddings = list(executor.map(elmo_embeddings, lyrics))\n",
    "    \n",
    "    # Generate BERT embeddings\n",
    "    bert_embeddings = list(executor.map(bert_embeddings, lyrics))\n",
    "\n",
    "# Combine ELMo and BERT embeddings\n",
    "combined_embeddings = pd.concat([pd.DataFrame(elmo_embeddings), pd.DataFrame(bert_embeddings)], axis=1)\n",
    "\n",
    "# Add the combined embeddings to your dataset\n",
    "dataset = pd.concat([dataset, combined_embeddings], axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ann-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
